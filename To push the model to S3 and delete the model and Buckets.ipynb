{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating bucket to push the model to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket \"mlops-tinybert-sentimentanalysis\" already exists.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'mlops-tinybert-sentimentanalysis'\n",
    "region = 'ap-south-1'\n",
    "\n",
    "def create_bucket(bucket_name, region):\n",
    "    location = {'LocationConstraint': region}\n",
    "    response = s3.list_buckets()\n",
    "    buckets = [bucket['Name'] for bucket in response['Buckets']]\n",
    "\n",
    "    if bucket_name not in buckets:\n",
    "        s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration=location)\n",
    "        print(f'Bucket \"{bucket_name}\" is created in \"{region}\" region.')\n",
    "    else:\n",
    "        print(f'Bucket \"{bucket_name}\" already exists.')\n",
    "\n",
    "create_bucket(bucket_name, region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push model to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "folder_path = r'C:\\Users\\Aniket\\Desktop\\MLOPS_UDEMY\\Projects\\Sentiment Classification Using TinyBert\\model'\n",
    "bucket_name = 'mlops-tinybert-sentimentanalysis'\n",
    "\n",
    "def upload_directory_to_s3(folder_path, bucket_name, s3_prefix=\"\"):\n",
    "    # Walkeing through the directory\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            # Constructing full local path\n",
    "            local_path = os.path.join(root, file)\n",
    "\n",
    "            # Construct the relative path and then the full S3 key\n",
    "            realtive_path = os.path.relpath(local_path, folder_path)\n",
    "            s3_key = os.path.join(s3_prefix, realtive_path).replace(\"\\\\\", \"/\")  # Replace Windows backslashes with S3-compatible slashes\n",
    "\n",
    "\n",
    "            try:\n",
    "                # Uploading the file to s3\n",
    "                s3.upload_file(local_path, bucket_name, s3_key)\n",
    "                print(f\"Uploaded {local_path} to s3://{bucket_name}/{s3_key}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f'Failed to upload {local_path}: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded C:\\Users\\Aniket\\Desktop\\MLOPS_UDEMY\\Projects\\Sentiment Classification Using TinyBert\\model\\config.json to s3://mlops-tinybert-sentimentanalysis/config.json\n",
      "Uploaded C:\\Users\\Aniket\\Desktop\\MLOPS_UDEMY\\Projects\\Sentiment Classification Using TinyBert\\model\\model.safetensors to s3://mlops-tinybert-sentimentanalysis/model.safetensors\n",
      "Uploaded C:\\Users\\Aniket\\Desktop\\MLOPS_UDEMY\\Projects\\Sentiment Classification Using TinyBert\\model\\model.txt to s3://mlops-tinybert-sentimentanalysis/model.txt\n",
      "Uploaded C:\\Users\\Aniket\\Desktop\\MLOPS_UDEMY\\Projects\\Sentiment Classification Using TinyBert\\model\\special_tokens_map.json to s3://mlops-tinybert-sentimentanalysis/special_tokens_map.json\n",
      "Uploaded C:\\Users\\Aniket\\Desktop\\MLOPS_UDEMY\\Projects\\Sentiment Classification Using TinyBert\\model\\tokenizer.json to s3://mlops-tinybert-sentimentanalysis/tokenizer.json\n",
      "Uploaded C:\\Users\\Aniket\\Desktop\\MLOPS_UDEMY\\Projects\\Sentiment Classification Using TinyBert\\model\\tokenizer_config.json to s3://mlops-tinybert-sentimentanalysis/tokenizer_config.json\n",
      "Uploaded C:\\Users\\Aniket\\Desktop\\MLOPS_UDEMY\\Projects\\Sentiment Classification Using TinyBert\\model\\training_args.bin to s3://mlops-tinybert-sentimentanalysis/training_args.bin\n",
      "Uploaded C:\\Users\\Aniket\\Desktop\\MLOPS_UDEMY\\Projects\\Sentiment Classification Using TinyBert\\model\\vocab.txt to s3://mlops-tinybert-sentimentanalysis/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "upload_directory_to_s3(folder_path, bucket_name, s3_prefix=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete all files from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_bucket(bucket_name):\n",
    "    response = s3.list_objects_v2(Bucket=bucket_name)\n",
    "\n",
    "    if 'Contents' in response:\n",
    "        for obj in response['Contents']:\n",
    "            print(f\"Deleting the file '{obj['Key']}'...\")\n",
    "            s3.delete_object(Bucket=bucket_name, Key=obj['Key'])\n",
    "            print(f\"The file '{obj['Key']}' has been deleted.\")\n",
    "    \n",
    "    print('The bucket is now empty and ready to be deleted from AWS S3.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting the file 'config.json'...\n",
      "The file 'config.json' has been deleted.\n",
      "Deleting the file 'model.safetensors'...\n",
      "The file 'model.safetensors' has been deleted.\n",
      "Deleting the file 'model.txt'...\n",
      "The file 'model.txt' has been deleted.\n",
      "Deleting the file 'special_tokens_map.json'...\n",
      "The file 'special_tokens_map.json' has been deleted.\n",
      "Deleting the file 'tokenizer.json'...\n",
      "The file 'tokenizer.json' has been deleted.\n",
      "Deleting the file 'tokenizer_config.json'...\n",
      "The file 'tokenizer_config.json' has been deleted.\n",
      "Deleting the file 'training_args.bin'...\n",
      "The file 'training_args.bin' has been deleted.\n",
      "Deleting the file 'vocab.txt'...\n",
      "The file 'vocab.txt' has been deleted.\n",
      "The bucket is now empty and ready to be deleted from AWS S3.\n"
     ]
    }
   ],
   "source": [
    "empty_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to empty files from the bucket and after that only we can delete the bucket\n",
    "def delete_bucket(bucket_name):\n",
    "    try:\n",
    "        s3.delete_bucket(Bucket = bucket_name)\n",
    "        print(f'Successfully deleted bucket \"{bucket_name}\"')\n",
    "    except Exception as e:\n",
    "        print(f'Failed to delete bucket \"{bucket_name}\" \\nbecause of the error:\"{e}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully deleted bucket \"mlops-tinybert-sentimentanalysis\"\n"
     ]
    }
   ],
   "source": [
    "delete_bucket(bucket_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
